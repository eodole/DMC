{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method I would like to try is a neural network. \n",
    "Here we can see that we have 127 input features and we know we have 3 output classes so we should use \n",
    "65 hidden neurons as in accordance with this stack overflow post \n",
    "https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import os\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.impute\n",
    "import sklearn.neighbors \n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import neural_network\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, make_scorer\n",
    "# import keras \n",
    "# from keras import layers\n",
    "# from keras import ops \n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data as tud\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 117)\n",
      "after group dv\n",
      "(8000, 127)\n"
     ]
    }
   ],
   "source": [
    "### Import and Clean Data\n",
    "# Import Training Data\n",
    "training_data= pd.read_csv(\"./Data/training_data.csv\", sep=\";\", decimal=',')\n",
    "\n",
    "# features and target split \n",
    "data_X = training_data.loc[:, training_data.columns != \"Class\"]\n",
    "data_X = data_X.loc[:, data_X.columns != \"Perform\"]\n",
    "\n",
    "data_Class = training_data.loc[:, \"Class\"]\n",
    "data_Perform = training_data.loc[:,\"Perform\"]\n",
    "\n",
    "# Change Class labels \n",
    "# Define the expected class mapping\n",
    "label_mapping = {0: 2, 1: 0, -1 : 1}  # Change according to your expected class order\n",
    "\n",
    "# Apply the mapping to the target variable\n",
    "data_Class = data_Class.map(label_mapping)\n",
    "\n",
    "# Take the names of only the numeric columns, i.e. columns other than group \n",
    "numeric_col =data_X.iloc[:,1:].columns # data without groups\n",
    "\n",
    "# Scale the data \n",
    "scaler=preprocessing.StandardScaler()\n",
    "data_X[numeric_col] = scaler.fit_transform(data_X[numeric_col])\n",
    "data_X.head()\n",
    "\n",
    "# Add Dummy Variables for Group\n",
    "print(data_X.shape)\n",
    "data_X = pd.get_dummies(data_X,\"Group_\",columns=[\"Group\"])\n",
    "print(\"after group dv\")\n",
    "print(data_X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute Data \n",
    "imp = sklearn.impute.SimpleImputer(strategy=\"median\")\n",
    "data_Xsimple = imp.fit_transform(data_X)\n",
    "imp = sklearn.impute.KNNImputer(n_neighbors=3,weights = \"uniform\")\n",
    "data_XkNN = imp.fit_transform(data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Given Training Data to Test/Train Split \n",
    "X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(data_Xsimple, data_Class, test_size=0.25, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom scorer Template \n",
    "def avg_err_cost(y_true, y_pred):\n",
    "    # Define the desired rows\n",
    "    row1 = [0, 1, 2]\n",
    "    row2 = [1, 0, 1]\n",
    "    row3 = [2, 1, 0]\n",
    "\n",
    "    cost_matrix = np.array([row1, row2, row3]) \n",
    "    confu_matrix = confusion_matrix(y_true, y_pred)\n",
    "    acc = 1 - np.sum(confu_matrix * cost_matrix)/len(y_true)\n",
    "    return  acc\n",
    "\n",
    "custom_scorer = make_scorer(avg_err_cost)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 127)\n",
      "(8000,)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000   # arbitrarily choosen \n",
    "\n",
    "# Create Data loaders \n",
    "\n",
    "print(data_Xsimple.shape)\n",
    "print(data_Class.shape)\n",
    "targets = torch.tensor(data_Class)\n",
    "inputs = torch.tensor(data_Xsimple)\n",
    "# print(t)\n",
    "# print(t.shape)\n",
    "# print(t2)\n",
    "# print(t2.shape)\n",
    "dataset = tud.TensorDataset(inputs, targets) # load  train data in pytorch form TensorDataset(inputs, targets)\n",
    "test_ds = tud.TensorDataset(inputs,targets) # load test data in pytorch form \n",
    "\n",
    "train_data_loader = tud.DataLoader(dataset, batch_size=batch_size) # allows for batchable content\n",
    "test_data_loader = tud.DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea for the neural network is to have two hidden layers that will have the average of the target and the previous layers number of nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = torch.nn.Sequential(\n",
    "            torch.nn.Linear(127,65 ), # Input -> H1: go from 127 to 65 nodes  \n",
    "            torch.nn.ReLU(), # activation\n",
    "            torch.nn.Linear(65,34 ), #  H1 -> H2: another layer of 65 nodes to 34 \n",
    "            torch.nn.ReLU(), # activation \n",
    "            torch.nn.Linear(34,3), # H2 -> output\n",
    "            )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        raw_out_values = self.linear_relu_stack(x)\n",
    "        return raw_out_values\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=127, out_features=65, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=65, out_features=34, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=34, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(dtype=torch.float32)\n",
    "print(model) # print the model structure "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think in the end I will get class predictions of the values $\\{0,1,2\\}$ so I think i will need to rename the data accordingly so that i properly predict the outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0457, -0.1670,  0.0924], device='mps:0', grad_fn=<LinearBackward0>)\n",
      "tensor([0.3296, 0.2920, 0.3784], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor(2, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "## Test \n",
    "X = torch.rand(127, device=device)\n",
    "logits = model(X)\n",
    "print(logits)\n",
    "pred_prob = nn.Softmax(dim=0)(logits)\n",
    "print(pred_prob)\n",
    "y_pred = pred_prob.argmax(0)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom pytorch loss function based on above \n",
    "def custom_loss(y_true, y_pred):\n",
    "    y_true = y_true.detach().numpy()\n",
    "    y_pred = y_pred.detach().numpy()\n",
    "    # print(y_true.shape)\n",
    "    # print(y_pred.shape)\n",
    "    row1 = [0, 1, 2]\n",
    "    row2 = [1, 0, 1]\n",
    "    row3 = [2, 1, 0]\n",
    "\n",
    "    cost_matrix = np.array([row1, row2, row3]) \n",
    "    confu_matrix = confusion_matrix(y_true, y_pred)\n",
    "    err = np.sum(confu_matrix * cost_matrix)/len(y_true)\n",
    "    return err \n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# Define optimizer using stochastic gradient descent\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of the box training function\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # print(type(X))\n",
    "        # print(type(y))\n",
    "        X, y = X.to(dtype=torch.float32), y.to(dtype=torch.float32) # fixed float64 bug\n",
    "\n",
    "        # Compute prediction\n",
    "        raw_out_val = model(X)\n",
    "        # print(\"rawoutshape\")\n",
    "        # print(raw_out_val.shape)\n",
    "        pred_prob = nn.Softmax(dim=1)(raw_out_val)  \n",
    "        # print(\"predprob shape\")\n",
    "        # print(pred_prob.shape)\n",
    "        # pred = pred_prob.argmax(1)# dont need this bc cross entropy loss expects probabilities\n",
    "        # print(\"pred shape\")\n",
    "        # print(pred.shape)\n",
    "        # print(\"next \")\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(pred_prob,y.long())\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of the box testing function \n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(dtype=torch.float32), y.to(dtype=torch.float32) # fixed float64 bug\n",
    "            # Compute prediction\n",
    "            raw_out_val = model(X)\n",
    "            pred = nn.Softmax(dim=1)(raw_out_val)\n",
    "            #pred = pred_prob.argmax(1) # dont need this bc cross entropy loss expects probabilities \n",
    "            test_loss += loss_fn(pred,y.long()).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.090176  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.090265 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.090101  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 43.6%, Avg loss: 1.090188 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.090026  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.090110 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.089951  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.090033 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.089877  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 43.6%, Avg loss: 1.089956 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.089802  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 43.6%, Avg loss: 1.089879 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.089727  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 43.6%, Avg loss: 1.089802 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.089653  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.089726 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.089579  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.089649 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.089504  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.089572 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.089430  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.089496 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.089356  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.089420 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.089283  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 43.9%, Avg loss: 1.089344 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.089209  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 43.9%, Avg loss: 1.089268 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.089135  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 43.9%, Avg loss: 1.089192 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.089062  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 43.9%, Avg loss: 1.089116 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.088988  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 1.089040 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.088915  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 1.088964 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.088842  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 1.088889 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.088769  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 1.088813 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.088696  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 1.088738 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.088623  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 1.088663 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.088550  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 1.088588 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.088478  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 1.088513 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.088405  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 1.088438 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.088333  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 1.088363 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.088261  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 1.088289 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.088189  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 1.088214 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.088117  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 1.088140 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1.088045  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.088066 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 1.087973  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.087991 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 1.087901  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.087917 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 1.087830  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.087843 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 1.087758  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.087769 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 1.087687  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.087696 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 1.087615  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.087622 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 1.087544  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 1.087549 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 1.087473  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.087475 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 1.087402  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 1.087402 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 1.087332  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 1.087328 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 1.087261  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.087255 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 1.087190  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.087182 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 1.087119  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.087109 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 1.087049  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 1.087036 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 1.086979  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 1.086964 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 1.086908  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.086891 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 1.086838  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 1.086818 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 1.086768  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 1.086746 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 1.086699  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.086674 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 1.086629  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.086602 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 1.086559  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.086529 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 1.086489  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.086457 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 1.086420  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.086385 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 1.086350  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 1.086314 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 1.086281  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 1.086242 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 1.086212  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 1.086170 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 1.086143  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.086099 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 1.086074  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.086027 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 1.086005  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.085956 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 1.085936  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.085885 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 1.085867  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 1.085814 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 1.085799  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.085742 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 1.085730  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 1.085672 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 1.085662  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.085601 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 1.085593  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.5%, Avg loss: 1.085530 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 1.085525  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.085459 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 1.085457  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.085389 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 1.085389  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.085318 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 1.085321  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.085248 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 1.085253  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.085178 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 1.085185  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.085108 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 1.085118  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.085038 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 1.085050  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 1.084968 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 1.084982  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.084898 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 1.084915  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.084828 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 1.084848  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.5%, Avg loss: 1.084758 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 1.084781  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.5%, Avg loss: 1.084689 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 1.084714  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.6%, Avg loss: 1.084619 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 1.084647  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.7%, Avg loss: 1.084550 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 1.084580  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.7%, Avg loss: 1.084481 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 1.084513  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.7%, Avg loss: 1.084411 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 1.084446  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.7%, Avg loss: 1.084342 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 1.084380  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 1.084273 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 1.084313  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 1.084204 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 1.084247  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 1.084136 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 1.084181  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.9%, Avg loss: 1.084067 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 1.084115  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 1.083998 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 1.084049  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 1.083930 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 1.083983  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 1.083861 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 1.083917  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 1.083793 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 1.083851  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 1.083725 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 1.083785  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.9%, Avg loss: 1.083657 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 1.083720  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 1.083588 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 1.083654  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.7%, Avg loss: 1.083521 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 1.083589  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.7%, Avg loss: 1.083453 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 1.083523  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.7%, Avg loss: 1.083385 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 1.083458  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 1.083317 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 1.083393  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 1.083250 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 1.083328  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.9%, Avg loss: 1.083182 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 1.083263  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 44.9%, Avg loss: 1.083115 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 1.083198  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.0%, Avg loss: 1.083047 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 1.083134  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.0%, Avg loss: 1.082980 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 1.083069  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.082913 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 1.083004  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.082846 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 1.082940  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.082779 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 1.082876  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.082712 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 1.082811  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.082645 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 1.082747  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.0%, Avg loss: 1.082578 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 1.082683  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.082512 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 1.082619  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.082445 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 1.082555  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.082379 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 1.082491  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.0%, Avg loss: 1.082312 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 1.082428  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.082246 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 1.082364  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.082180 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 1.082301  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.082114 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 1.082237  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.2%, Avg loss: 1.082048 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 1.082174  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.2%, Avg loss: 1.081982 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 1.082110  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.081916 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 1.082047  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.081850 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 1.081984  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.081785 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 1.081921  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.081719 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 1.081858  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.2%, Avg loss: 1.081653 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 1.081795  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.2%, Avg loss: 1.081588 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 1.081732  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.3%, Avg loss: 1.081523 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 1.081669  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.3%, Avg loss: 1.081457 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 1.081606  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.3%, Avg loss: 1.081392 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 1.081544  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.4%, Avg loss: 1.081327 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 1.081481  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.081262 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 1.081419  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.081197 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 1.081357  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.081132 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 1.081294  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.081067 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 1.081232  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.081003 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 1.081170  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.6%, Avg loss: 1.080938 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 1.081108  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.6%, Avg loss: 1.080874 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 1.081046  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.7%, Avg loss: 1.080809 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 1.080984  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.7%, Avg loss: 1.080745 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 1.080922  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.7%, Avg loss: 1.080680 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 1.080861  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.8%, Avg loss: 1.080616 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 1.080799  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.8%, Avg loss: 1.080552 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 1.080738  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.9%, Avg loss: 1.080488 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 1.080676  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.9%, Avg loss: 1.080424 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 1.080615  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.0%, Avg loss: 1.080360 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 1.080553  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.9%, Avg loss: 1.080296 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 1.080492  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.9%, Avg loss: 1.080233 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 1.080431  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 45.9%, Avg loss: 1.080169 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 1.080370  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.0%, Avg loss: 1.080106 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 1.080309  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.1%, Avg loss: 1.080042 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 1.080248  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.1%, Avg loss: 1.079979 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 1.080187  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.1%, Avg loss: 1.079915 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 1.080127  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.1%, Avg loss: 1.079852 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 1.080066  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.1%, Avg loss: 1.079789 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 1.080005  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.0%, Avg loss: 1.079726 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 1.079945  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.0%, Avg loss: 1.079663 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 1.079884  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.0%, Avg loss: 1.079600 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 1.079824  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.1%, Avg loss: 1.079537 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 1.079764  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.1%, Avg loss: 1.079474 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 1.079703  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.079412 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 1.079643  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.079349 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 1.079583  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.079287 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 1.079523  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.079224 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 1.079464  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.079162 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 1.079404  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.079100 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 1.079344  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.079037 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 1.079284  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.078975 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 1.079225  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.078913 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 1.079165  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.078851 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 1.079106  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.078789 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 1.079046  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.3%, Avg loss: 1.078727 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 1.078988  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.078666 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 1.078928  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.3%, Avg loss: 1.078604 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 1.078869  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.3%, Avg loss: 1.078542 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 1.078810  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 1.078481 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 1.078751  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.3%, Avg loss: 1.078419 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 1.078692  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.3%, Avg loss: 1.078358 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 1.078634  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 1.078297 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 1.078575  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 1.078236 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 1.078516  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 1.078174 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 1.078458  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 1.078113 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 1.078399  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 1.078052 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 1.078341  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 1.077991 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 1.078282  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 1.077931 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 1.078224  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 1.077870 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 1.078166  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.077809 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 1.078108  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.077749 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 1.078050  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.077688 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 1.077992  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.077628 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 1.077934  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.077567 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 1.077876  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.077507 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 1.077819  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.077447 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 1.077761  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.077387 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 1.077704  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.077327 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 1.077646  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.077267 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 1.077589  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.6%, Avg loss: 1.077207 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 1.077532  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.077147 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 1.077474  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.077087 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 1.077417  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.077028 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 1.077360  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.076968 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 1.077303  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 1.076908 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 1.077246  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.076849 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 1.077189  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.076790 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 1.077132  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.076730 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 1.077076  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.076671 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 1.077019  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.076612 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 1.076963  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.076553 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 1.076906  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.076494 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 1.076850  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.076435 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 1.076794  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.076376 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 1.076737  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.6%, Avg loss: 1.076318 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 1.076681  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 1.076259 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 1.076625  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 1.076200 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 1.076569  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 1.076142 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 1.076513  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 1.076083 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 1.076457  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 1.076025 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 1.076401  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 1.075967 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 1.076346  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.075908 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 1.076290  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.075850 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 1.076234  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.075792 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 1.076179  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.075734 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 1.076123  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.075676 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 1.076068  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.075618 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 1.076013  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.075560 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 1.075957  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.075503 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 1.075902  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 1.075445 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 1.075847  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.075387 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 1.075792  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.075330 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 1.075737  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.075273 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 1.075682  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 1.075215 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 1.075627  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.075158 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 1.075572  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.075101 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 1.075518  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.075043 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 1.075463  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.074986 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 1.075409  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.074929 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 1.075354  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.074872 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 1.075300  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.074816 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 1.075246  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.074759 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 1.075191  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.074702 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 1.075137  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.074645 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 1.075083  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.074589 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 1.075029  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.074532 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 1.074975  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.074476 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 1.074921  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.074419 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 1.074867  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.074363 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 1.074814  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.074307 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 1.074760  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.074250 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 1.074706  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.074194 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 1.074653  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.074138 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 1.074599  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.074082 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 1.074546  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.074026 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 1.074492  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.073970 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 1.074439  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.073915 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 1.074386  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.073859 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 1.074333  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.073803 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 1.074280  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.073748 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 1.074227  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 1.073692 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 1.074173  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.073637 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 1.074121  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.073581 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 1.074068  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.073526 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 1.074015  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.073471 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 1.073962  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 1.073415 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 1.073910  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.073360 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 1.073857  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.073305 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 1.073804  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 1.073250 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 1.073752  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 1.073195 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 1.073700  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.073140 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 1.073647  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 1.073085 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 1.073595  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.073031 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 1.073543  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.072976 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 1.073491  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 1.072921 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 1.073439  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 1.072867 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 1.073387  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 1.072813 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 1.073335  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.072758 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 1.073283  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.072704 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 1.073231  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.072650 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 1.073180  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.072595 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 1.073128  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.072541 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 1.073076  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.072487 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 1.073025  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.072433 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 1.072974  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.072379 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 1.072922  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.072325 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 1.072871  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.072272 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 1.072820  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.072218 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 1.072769  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.072164 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 1.072718  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.072111 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 1.072667  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.072057 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 1.072616  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.072004 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 1.072565  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.071950 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 1.072514  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.071897 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 1.072463  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.071844 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 1.072412  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.071791 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 1.072362  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.071738 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 1.072311  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.071685 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 1.072261  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.071632 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 1.072210  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.071579 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 1.072160  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.071526 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 1.072110  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.071473 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 1.072059  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.071420 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 1.072009  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.071368 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 1.071959  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.071315 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 1.071909  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.071263 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 1.071859  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.071210 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 1.071809  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.071158 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 1.071759  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.071105 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 1.071710  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.071053 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 1.071660  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.071001 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 1.071610  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.070949 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 1.071560  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.070897 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 1.071511  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.070845 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 1.071461  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.070793 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 1.071412  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.070741 \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 1.071363  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.070689 \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 1.071313  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.070637 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 1.071264  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.070586 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 1.071215  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.070534 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 1.071166  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.070482 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 1.071117  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.070431 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 1.071068  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.070379 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 1.071019  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.070328 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 1.070970  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.070277 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 1.070921  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.070226 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 1.070872  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.070174 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 1.070824  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.070123 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 1.070775  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.070072 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 1.070727  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.070021 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 1.070678  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.069970 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 1.070630  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.069919 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 1.070582  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.069869 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 1.070533  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.069818 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 1.070485  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.069767 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 1.070437  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.069717 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 1.070389  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.069666 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 1.070341  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.069616 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 1.070293  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.069565 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 1.070245  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.069515 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 1.070197  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.069465 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 1.070150  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.069415 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 1.070102  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.069365 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 1.070055  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.069314 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 1.070007  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.069264 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 1.069960  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.069215 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 1.069912  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.069165 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 1.069865  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.069115 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 1.069818  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.069065 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 1.069770  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.069015 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 1.069723  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.068966 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 1.069676  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.068916 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 1.069629  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.068867 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 1.069582  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.068817 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 1.069535  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.068768 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 1.069488  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.068719 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 1.069442  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.068669 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 1.069395  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.068620 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 1.069348  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.068571 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 1.069301  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.068522 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 1.069255  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.068473 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 1.069208  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.068424 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 1.069162  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.068375 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 1.069116  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.068326 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 1.069069  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.068277 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 1.069023  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.068229 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 1.068977  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.068180 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 1.068931  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.068131 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 1.068884  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.068083 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 1.068838  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.068034 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 1.068792  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.067986 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 1.068747  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.067938 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 1.068701  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.067889 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 1.068655  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.067841 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 1.068609  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.067793 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 1.068563  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.067745 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 1.068518  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.067697 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 1.068472  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.067649 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 1.068427  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.067601 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 1.068381  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.067553 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 1.068336  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.067505 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 1.068291  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.067458 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 1.068246  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.067410 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 1.068200  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.067362 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 1.068155  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.067315 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 1.068110  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.067267 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 1.068065  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.067220 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 1.068020  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.067172 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 1.067975  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.067125 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 1.067930  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.067078 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 1.067886  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.067031 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 1.067841  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.066983 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 1.067796  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.066936 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 1.067752  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.066889 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 1.067707  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.066842 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 1.067663  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.066795 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 1.067618  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.066749 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 1.067574  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.066702 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 1.067530  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.066655 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 1.067485  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.066608 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 1.067441  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.066562 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 1.067397  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.066515 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 1.067353  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.066469 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 1.067309  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.066422 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 1.067265  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.066376 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 1.067221  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.066330 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 1.067178  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.066283 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 1.067134  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.066237 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 1.067090  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.066191 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 1.067046  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.066145 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 1.067003  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.066099 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 1.066959  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.066053 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 1.066916  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.066007 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 1.066872  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.065961 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 1.066829  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.065915 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 1.066785  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.065870 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 1.066742  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.065824 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 1.066699  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.065778 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 1.066656  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.065733 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 1.066613  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.065687 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 1.066570  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.065642 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 1.066527  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.065596 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 1.066484  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.065551 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 1.066441  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.065506 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 1.066398  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.065460 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 1.066355  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.065415 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 1.066313  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.065370 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 1.066270  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.065325 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 1.066227  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.065280 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 1.066185  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.065235 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 1.066142  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.065190 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 1.066100  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.065145 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 1.066057  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.065100 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 1.066015  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.065056 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 1.065973  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.065011 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 1.065930  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.064966 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 1.065888  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.064922 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 1.065846  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.064877 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 1.065804  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.064833 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 1.065762  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.064788 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 1.065720  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.064744 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 1.065678  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.064700 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 1.065636  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.064655 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 1.065594  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.064611 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 1.065552  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.064567 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 1.065511  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.064523 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 1.065469  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.064479 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 1.065428  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.064435 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 1.065386  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.064391 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 1.065344  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.064347 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 1.065303  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.064304 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 1.065261  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.064260 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 1.065220  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.064216 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 1.065179  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.064172 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 1.065137  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.064129 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 1.065096  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.064085 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 1.065055  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.064042 \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 1.065014  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.063998 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 1.064973  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.063955 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 1.064932  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.063912 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 1.064891  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.063868 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 1.064850  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.063825 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 1.064809  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.063782 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 1.064768  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.063739 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 1.064727  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.063696 \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 1.064687  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.063653 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 1.064646  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.063610 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 1.064605  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.063567 \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 1.064565  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.063524 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 1.064524  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.063482 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 1.064484  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.063439 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 1.064443  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.063396 \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 1.064403  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.063354 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 1.064363  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.063311 \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 1.064323  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.063269 \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 1.064282  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.063226 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 1.064242  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.063184 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 1.064202  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.063141 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 1.064162  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.063099 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 1.064122  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.063057 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 1.064082  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.063015 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 1.064042  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.062972 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 1.064003  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.062930 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 1.063963  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.062888 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 1.063923  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.062846 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 1.063883  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.062804 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 1.063844  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.062763 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 1.063804  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.062721 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 1.063765  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.062679 \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 1.063725  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.062637 \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 1.063686  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.062596 \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 1.063646  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.062554 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 1.063607  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.062512 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 1.063568  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.062471 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 1.063528  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.062429 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 1.063489  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.062388 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 1.063450  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.062347 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 1.063411  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.062305 \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 1.063372  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.062264 \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 1.063333  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.062223 \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 1.063294  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.062182 \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 1.063255  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.062141 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 1.063216  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.062100 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 1.063178  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.062059 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 1.063139  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.062018 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 1.063100  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061977 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 1.063062  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061936 \n",
      "\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "loss: 1.063023  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061895 \n",
      "\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "loss: 1.062985  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061855 \n",
      "\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "loss: 1.062946  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061814 \n",
      "\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "loss: 1.062908  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061774 \n",
      "\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "loss: 1.062870  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061733 \n",
      "\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "loss: 1.062831  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061692 \n",
      "\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "loss: 1.062793  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061652 \n",
      "\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "loss: 1.062755  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061612 \n",
      "\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "loss: 1.062717  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061571 \n",
      "\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "loss: 1.062679  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061531 \n",
      "\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "loss: 1.062641  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061491 \n",
      "\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "loss: 1.062603  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061451 \n",
      "\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "loss: 1.062565  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061411 \n",
      "\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "loss: 1.062526  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061370 \n",
      "\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "loss: 1.062489  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061330 \n",
      "\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "loss: 1.062451  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061290 \n",
      "\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "loss: 1.062413  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061251 \n",
      "\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "loss: 1.062376  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061211 \n",
      "\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "loss: 1.062338  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061171 \n",
      "\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "loss: 1.062300  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061131 \n",
      "\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "loss: 1.062263  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.061091 \n",
      "\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "loss: 1.062225  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.061052 \n",
      "\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "loss: 1.062188  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.061012 \n",
      "\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "loss: 1.062150  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.060973 \n",
      "\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "loss: 1.062113  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.060933 \n",
      "\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "loss: 1.062076  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.060894 \n",
      "\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "loss: 1.062038  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.060854 \n",
      "\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "loss: 1.062001  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060815 \n",
      "\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "loss: 1.061964  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060776 \n",
      "\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "loss: 1.061927  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060736 \n",
      "\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "loss: 1.061890  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060697 \n",
      "\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "loss: 1.061853  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060658 \n",
      "\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "loss: 1.061816  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060619 \n",
      "\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "loss: 1.061779  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060580 \n",
      "\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "loss: 1.061742  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060541 \n",
      "\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "loss: 1.061705  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060502 \n",
      "\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "loss: 1.061669  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060463 \n",
      "\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "loss: 1.061632  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060424 \n",
      "\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "loss: 1.061595  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060385 \n",
      "\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "loss: 1.061559  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060347 \n",
      "\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "loss: 1.061522  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060308 \n",
      "\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "loss: 1.061486  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060269 \n",
      "\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "loss: 1.061449  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060231 \n",
      "\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "loss: 1.061413  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060192 \n",
      "\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "loss: 1.061376  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060154 \n",
      "\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "loss: 1.061340  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060115 \n",
      "\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "loss: 1.061304  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060077 \n",
      "\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "loss: 1.061267  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060039 \n",
      "\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "loss: 1.061231  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.060000 \n",
      "\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "loss: 1.061195  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.059962 \n",
      "\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "loss: 1.061159  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.059924 \n",
      "\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "loss: 1.061123  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.059886 \n",
      "\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "loss: 1.061087  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.059848 \n",
      "\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "loss: 1.061051  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.059810 \n",
      "\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "loss: 1.061015  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.059772 \n",
      "\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "loss: 1.060979  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.059734 \n",
      "\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "loss: 1.060943  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.059696 \n",
      "\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "loss: 1.060907  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.059658 \n",
      "\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "loss: 1.060872  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.059620 \n",
      "\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "loss: 1.060836  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.059582 \n",
      "\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "loss: 1.060801  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.059545 \n",
      "\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "loss: 1.060765  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.059507 \n",
      "\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "loss: 1.060729  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.059469 \n",
      "\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "loss: 1.060694  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.059432 \n",
      "\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "loss: 1.060658  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.059394 \n",
      "\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "loss: 1.060623  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.059357 \n",
      "\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "loss: 1.060588  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.059319 \n",
      "\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "loss: 1.060552  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.059282 \n",
      "\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "loss: 1.060517  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.059245 \n",
      "\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "loss: 1.060482  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.059208 \n",
      "\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "loss: 1.060447  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.059170 \n",
      "\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "loss: 1.060412  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.059133 \n",
      "\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "loss: 1.060377  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.059096 \n",
      "\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "loss: 1.060342  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.059059 \n",
      "\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "loss: 1.060306  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.059022 \n",
      "\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "loss: 1.060272  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058985 \n",
      "\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "loss: 1.060237  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058948 \n",
      "\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "loss: 1.060202  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058911 \n",
      "\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "loss: 1.060167  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058874 \n",
      "\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "loss: 1.060132  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058838 \n",
      "\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "loss: 1.060098  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058801 \n",
      "\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "loss: 1.060063  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058764 \n",
      "\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "loss: 1.060029  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058727 \n",
      "\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "loss: 1.059994  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058691 \n",
      "\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "loss: 1.059960  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058654 \n",
      "\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "loss: 1.059925  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058618 \n",
      "\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "loss: 1.059891  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058581 \n",
      "\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "loss: 1.059856  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058545 \n",
      "\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "loss: 1.059822  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058509 \n",
      "\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "loss: 1.059788  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058472 \n",
      "\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "loss: 1.059753  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058436 \n",
      "\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "loss: 1.059719  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058400 \n",
      "\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "loss: 1.059685  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058364 \n",
      "\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "loss: 1.059651  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058327 \n",
      "\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "loss: 1.059617  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058291 \n",
      "\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "loss: 1.059583  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058255 \n",
      "\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "loss: 1.059549  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058219 \n",
      "\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "loss: 1.059515  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058183 \n",
      "\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "loss: 1.059481  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058147 \n",
      "\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "loss: 1.059448  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058112 \n",
      "\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "loss: 1.059414  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058076 \n",
      "\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "loss: 1.059380  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058040 \n",
      "\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "loss: 1.059346  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.058004 \n",
      "\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "loss: 1.059313  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057969 \n",
      "\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "loss: 1.059279  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057933 \n",
      "\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "loss: 1.059245  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057897 \n",
      "\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "loss: 1.059212  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057862 \n",
      "\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "loss: 1.059178  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057826 \n",
      "\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "loss: 1.059145  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057791 \n",
      "\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "loss: 1.059112  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057755 \n",
      "\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "loss: 1.059078  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057720 \n",
      "\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "loss: 1.059045  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057685 \n",
      "\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "loss: 1.059012  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057650 \n",
      "\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "loss: 1.058979  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057614 \n",
      "\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "loss: 1.058946  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057579 \n",
      "\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "loss: 1.058913  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057544 \n",
      "\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "loss: 1.058879  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057509 \n",
      "\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "loss: 1.058846  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057474 \n",
      "\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "loss: 1.058813  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057439 \n",
      "\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "loss: 1.058781  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057404 \n",
      "\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "loss: 1.058748  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057369 \n",
      "\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "loss: 1.058715  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057334 \n",
      "\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "loss: 1.058682  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057299 \n",
      "\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "loss: 1.058649  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057265 \n",
      "\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "loss: 1.058616  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057230 \n",
      "\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "loss: 1.058584  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057195 \n",
      "\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "loss: 1.058551  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057161 \n",
      "\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "loss: 1.058519  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057126 \n",
      "\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "loss: 1.058486  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057092 \n",
      "\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "loss: 1.058454  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057057 \n",
      "\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "loss: 1.058421  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.057023 \n",
      "\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "loss: 1.058389  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056988 \n",
      "\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "loss: 1.058357  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056954 \n",
      "\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "loss: 1.058324  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056920 \n",
      "\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "loss: 1.058292  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056885 \n",
      "\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "loss: 1.058260  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056851 \n",
      "\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "loss: 1.058227  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056817 \n",
      "\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "loss: 1.058196  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056783 \n",
      "\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "loss: 1.058163  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056749 \n",
      "\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "loss: 1.058131  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056715 \n",
      "\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "loss: 1.058099  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056681 \n",
      "\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "loss: 1.058067  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056647 \n",
      "\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "loss: 1.058035  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056613 \n",
      "\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "loss: 1.058003  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056579 \n",
      "\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "loss: 1.057972  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056545 \n",
      "\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "loss: 1.057940  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056511 \n",
      "\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "loss: 1.057908  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056478 \n",
      "\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "loss: 1.057876  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056444 \n",
      "\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "loss: 1.057845  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056410 \n",
      "\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "loss: 1.057813  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056377 \n",
      "\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "loss: 1.057781  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056343 \n",
      "\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "loss: 1.057750  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056310 \n",
      "\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "loss: 1.057718  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056276 \n",
      "\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "loss: 1.057687  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056243 \n",
      "\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "loss: 1.057655  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056209 \n",
      "\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "loss: 1.057624  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056176 \n",
      "\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "loss: 1.057593  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056143 \n",
      "\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "loss: 1.057561  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056110 \n",
      "\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "loss: 1.057530  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056076 \n",
      "\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "loss: 1.057499  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056043 \n",
      "\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "loss: 1.057468  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.056010 \n",
      "\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "loss: 1.057437  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055977 \n",
      "\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "loss: 1.057405  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055944 \n",
      "\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "loss: 1.057374  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055911 \n",
      "\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "loss: 1.057343  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055878 \n",
      "\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "loss: 1.057312  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055845 \n",
      "\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "loss: 1.057281  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055812 \n",
      "\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "loss: 1.057251  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055780 \n",
      "\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "loss: 1.057220  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055747 \n",
      "\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "loss: 1.057189  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055714 \n",
      "\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "loss: 1.057158  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055681 \n",
      "\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "loss: 1.057127  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055649 \n",
      "\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "loss: 1.057097  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055616 \n",
      "\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "loss: 1.057066  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055583 \n",
      "\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "loss: 1.057035  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055551 \n",
      "\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "loss: 1.057005  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055518 \n",
      "\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "loss: 1.056974  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055486 \n",
      "\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "loss: 1.056944  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055454 \n",
      "\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "loss: 1.056913  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055421 \n",
      "\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "loss: 1.056883  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055389 \n",
      "\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "loss: 1.056853  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055357 \n",
      "\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "loss: 1.056822  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055325 \n",
      "\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "loss: 1.056792  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055292 \n",
      "\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "loss: 1.056762  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055260 \n",
      "\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "loss: 1.056732  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055228 \n",
      "\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "loss: 1.056701  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055196 \n",
      "\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "loss: 1.056671  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055164 \n",
      "\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "loss: 1.056641  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055132 \n",
      "\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "loss: 1.056611  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055100 \n",
      "\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "loss: 1.056581  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055068 \n",
      "\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "loss: 1.056551  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055037 \n",
      "\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "loss: 1.056521  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.055005 \n",
      "\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "loss: 1.056491  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054973 \n",
      "\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "loss: 1.056462  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054941 \n",
      "\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "loss: 1.056432  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054910 \n",
      "\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "loss: 1.056402  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054878 \n",
      "\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "loss: 1.056372  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054846 \n",
      "\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "loss: 1.056343  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054815 \n",
      "\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "loss: 1.056313  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054784 \n",
      "\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "loss: 1.056283  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054752 \n",
      "\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "loss: 1.056254  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054721 \n",
      "\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "loss: 1.056224  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054689 \n",
      "\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "loss: 1.056195  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054658 \n",
      "\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "loss: 1.056165  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054627 \n",
      "\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "loss: 1.056136  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054596 \n",
      "\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "loss: 1.056107  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054564 \n",
      "\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "loss: 1.056077  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054533 \n",
      "\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "loss: 1.056048  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054502 \n",
      "\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "loss: 1.056019  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054471 \n",
      "\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "loss: 1.055990  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054440 \n",
      "\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "loss: 1.055960  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054409 \n",
      "\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "loss: 1.055932  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054378 \n",
      "\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "loss: 1.055902  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054347 \n",
      "\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "loss: 1.055873  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054316 \n",
      "\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "loss: 1.055844  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054286 \n",
      "\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "loss: 1.055815  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054255 \n",
      "\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "loss: 1.055787  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054224 \n",
      "\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "loss: 1.055758  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054193 \n",
      "\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "loss: 1.055729  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054163 \n",
      "\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "loss: 1.055700  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054132 \n",
      "\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "loss: 1.055671  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054102 \n",
      "\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "loss: 1.055642  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054071 \n",
      "\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "loss: 1.055614  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054041 \n",
      "\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "loss: 1.055585  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.054010 \n",
      "\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "loss: 1.055557  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.053980 \n",
      "\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "loss: 1.055528  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.053950 \n",
      "\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "loss: 1.055500  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.053919 \n",
      "\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "loss: 1.055471  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.053889 \n",
      "\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "loss: 1.055443  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.053859 \n",
      "\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "loss: 1.055414  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.053829 \n",
      "\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "loss: 1.055386  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.053799 \n",
      "\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "loss: 1.055358  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.053768 \n",
      "\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "loss: 1.055329  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.053738 \n",
      "\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "loss: 1.055301  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.053708 \n",
      "\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "loss: 1.055273  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.053678 \n",
      "\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "loss: 1.055245  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.053648 \n",
      "\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "loss: 1.055217  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.053619 \n",
      "\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "loss: 1.055189  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.053589 \n",
      "\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "loss: 1.055161  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.053559 \n",
      "\n",
      "Epoch 740\n",
      "-------------------------------\n",
      "loss: 1.055133  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.053529 \n",
      "\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "loss: 1.055105  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.053499 \n",
      "\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "loss: 1.055077  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.053470 \n",
      "\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "loss: 1.055049  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.053440 \n",
      "\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "loss: 1.055021  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.053410 \n",
      "\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "loss: 1.054993  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.053381 \n",
      "\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "loss: 1.054965  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.053351 \n",
      "\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "loss: 1.054938  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.053322 \n",
      "\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "loss: 1.054910  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.053292 \n",
      "\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "loss: 1.054882  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.053263 \n",
      "\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "loss: 1.054855  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.053233 \n",
      "\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "loss: 1.054827  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.053204 \n",
      "\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "loss: 1.054800  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.053175 \n",
      "\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "loss: 1.054772  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.053146 \n",
      "\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "loss: 1.054744  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.053116 \n",
      "\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "loss: 1.054717  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.053087 \n",
      "\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "loss: 1.054690  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.053058 \n",
      "\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "loss: 1.054662  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.053029 \n",
      "\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "loss: 1.054635  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.053000 \n",
      "\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "loss: 1.054608  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052971 \n",
      "\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "loss: 1.054580  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052942 \n",
      "\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "loss: 1.054553  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052913 \n",
      "\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "loss: 1.054526  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052884 \n",
      "\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "loss: 1.054499  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052855 \n",
      "\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "loss: 1.054472  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052826 \n",
      "\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "loss: 1.054445  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052798 \n",
      "\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "loss: 1.054418  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052769 \n",
      "\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "loss: 1.054391  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052740 \n",
      "\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "loss: 1.054364  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052712 \n",
      "\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "loss: 1.054337  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052683 \n",
      "\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "loss: 1.054310  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052654 \n",
      "\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "loss: 1.054283  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052626 \n",
      "\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "loss: 1.054256  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052597 \n",
      "\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "loss: 1.054229  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052569 \n",
      "\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "loss: 1.054203  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052540 \n",
      "\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "loss: 1.054176  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052512 \n",
      "\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "loss: 1.054149  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052484 \n",
      "\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "loss: 1.054123  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052455 \n",
      "\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "loss: 1.054096  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052427 \n",
      "\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "loss: 1.054070  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052399 \n",
      "\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "loss: 1.054043  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052371 \n",
      "\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "loss: 1.054017  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052342 \n",
      "\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "loss: 1.053990  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052314 \n",
      "\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "loss: 1.053964  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052286 \n",
      "\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "loss: 1.053937  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.052258 \n",
      "\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "loss: 1.053911  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.052230 \n",
      "\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "loss: 1.053885  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052202 \n",
      "\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "loss: 1.053858  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052174 \n",
      "\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "loss: 1.053832  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052146 \n",
      "\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "loss: 1.053806  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052118 \n",
      "\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "loss: 1.053780  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052091 \n",
      "\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "loss: 1.053753  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052063 \n",
      "\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "loss: 1.053727  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052035 \n",
      "\n",
      "Epoch 793\n",
      "-------------------------------\n",
      "loss: 1.053701  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.052007 \n",
      "\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "loss: 1.053675  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051980 \n",
      "\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "loss: 1.053649  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051952 \n",
      "\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "loss: 1.053623  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051924 \n",
      "\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "loss: 1.053597  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051897 \n",
      "\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "loss: 1.053572  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051869 \n",
      "\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "loss: 1.053545  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051842 \n",
      "\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "loss: 1.053520  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051814 \n",
      "\n",
      "Epoch 801\n",
      "-------------------------------\n",
      "loss: 1.053494  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051787 \n",
      "\n",
      "Epoch 802\n",
      "-------------------------------\n",
      "loss: 1.053468  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051759 \n",
      "\n",
      "Epoch 803\n",
      "-------------------------------\n",
      "loss: 1.053443  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051732 \n",
      "\n",
      "Epoch 804\n",
      "-------------------------------\n",
      "loss: 1.053417  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051705 \n",
      "\n",
      "Epoch 805\n",
      "-------------------------------\n",
      "loss: 1.053391  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051677 \n",
      "\n",
      "Epoch 806\n",
      "-------------------------------\n",
      "loss: 1.053366  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051650 \n",
      "\n",
      "Epoch 807\n",
      "-------------------------------\n",
      "loss: 1.053340  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051623 \n",
      "\n",
      "Epoch 808\n",
      "-------------------------------\n",
      "loss: 1.053314  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051596 \n",
      "\n",
      "Epoch 809\n",
      "-------------------------------\n",
      "loss: 1.053289  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051569 \n",
      "\n",
      "Epoch 810\n",
      "-------------------------------\n",
      "loss: 1.053264  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051542 \n",
      "\n",
      "Epoch 811\n",
      "-------------------------------\n",
      "loss: 1.053238  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051515 \n",
      "\n",
      "Epoch 812\n",
      "-------------------------------\n",
      "loss: 1.053213  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051488 \n",
      "\n",
      "Epoch 813\n",
      "-------------------------------\n",
      "loss: 1.053187  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051461 \n",
      "\n",
      "Epoch 814\n",
      "-------------------------------\n",
      "loss: 1.053162  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051434 \n",
      "\n",
      "Epoch 815\n",
      "-------------------------------\n",
      "loss: 1.053137  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051407 \n",
      "\n",
      "Epoch 816\n",
      "-------------------------------\n",
      "loss: 1.053111  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051380 \n",
      "\n",
      "Epoch 817\n",
      "-------------------------------\n",
      "loss: 1.053086  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051353 \n",
      "\n",
      "Epoch 818\n",
      "-------------------------------\n",
      "loss: 1.053061  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051326 \n",
      "\n",
      "Epoch 819\n",
      "-------------------------------\n",
      "loss: 1.053036  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051299 \n",
      "\n",
      "Epoch 820\n",
      "-------------------------------\n",
      "loss: 1.053011  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051273 \n",
      "\n",
      "Epoch 821\n",
      "-------------------------------\n",
      "loss: 1.052985  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051246 \n",
      "\n",
      "Epoch 822\n",
      "-------------------------------\n",
      "loss: 1.052960  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051219 \n",
      "\n",
      "Epoch 823\n",
      "-------------------------------\n",
      "loss: 1.052935  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051193 \n",
      "\n",
      "Epoch 824\n",
      "-------------------------------\n",
      "loss: 1.052910  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051166 \n",
      "\n",
      "Epoch 825\n",
      "-------------------------------\n",
      "loss: 1.052886  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051140 \n",
      "\n",
      "Epoch 826\n",
      "-------------------------------\n",
      "loss: 1.052861  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051113 \n",
      "\n",
      "Epoch 827\n",
      "-------------------------------\n",
      "loss: 1.052836  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051087 \n",
      "\n",
      "Epoch 828\n",
      "-------------------------------\n",
      "loss: 1.052811  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051060 \n",
      "\n",
      "Epoch 829\n",
      "-------------------------------\n",
      "loss: 1.052786  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051034 \n",
      "\n",
      "Epoch 830\n",
      "-------------------------------\n",
      "loss: 1.052761  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.051007 \n",
      "\n",
      "Epoch 831\n",
      "-------------------------------\n",
      "loss: 1.052737  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050981 \n",
      "\n",
      "Epoch 832\n",
      "-------------------------------\n",
      "loss: 1.052712  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050955 \n",
      "\n",
      "Epoch 833\n",
      "-------------------------------\n",
      "loss: 1.052687  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050928 \n",
      "\n",
      "Epoch 834\n",
      "-------------------------------\n",
      "loss: 1.052662  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050902 \n",
      "\n",
      "Epoch 835\n",
      "-------------------------------\n",
      "loss: 1.052638  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050876 \n",
      "\n",
      "Epoch 836\n",
      "-------------------------------\n",
      "loss: 1.052613  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050850 \n",
      "\n",
      "Epoch 837\n",
      "-------------------------------\n",
      "loss: 1.052589  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050824 \n",
      "\n",
      "Epoch 838\n",
      "-------------------------------\n",
      "loss: 1.052564  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050798 \n",
      "\n",
      "Epoch 839\n",
      "-------------------------------\n",
      "loss: 1.052540  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050772 \n",
      "\n",
      "Epoch 840\n",
      "-------------------------------\n",
      "loss: 1.052515  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050746 \n",
      "\n",
      "Epoch 841\n",
      "-------------------------------\n",
      "loss: 1.052491  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050720 \n",
      "\n",
      "Epoch 842\n",
      "-------------------------------\n",
      "loss: 1.052466  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050694 \n",
      "\n",
      "Epoch 843\n",
      "-------------------------------\n",
      "loss: 1.052442  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050668 \n",
      "\n",
      "Epoch 844\n",
      "-------------------------------\n",
      "loss: 1.052418  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050642 \n",
      "\n",
      "Epoch 845\n",
      "-------------------------------\n",
      "loss: 1.052394  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050616 \n",
      "\n",
      "Epoch 846\n",
      "-------------------------------\n",
      "loss: 1.052369  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050590 \n",
      "\n",
      "Epoch 847\n",
      "-------------------------------\n",
      "loss: 1.052345  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050564 \n",
      "\n",
      "Epoch 848\n",
      "-------------------------------\n",
      "loss: 1.052321  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050539 \n",
      "\n",
      "Epoch 849\n",
      "-------------------------------\n",
      "loss: 1.052296  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050513 \n",
      "\n",
      "Epoch 850\n",
      "-------------------------------\n",
      "loss: 1.052272  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050487 \n",
      "\n",
      "Epoch 851\n",
      "-------------------------------\n",
      "loss: 1.052248  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050462 \n",
      "\n",
      "Epoch 852\n",
      "-------------------------------\n",
      "loss: 1.052224  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050436 \n",
      "\n",
      "Epoch 853\n",
      "-------------------------------\n",
      "loss: 1.052200  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050410 \n",
      "\n",
      "Epoch 854\n",
      "-------------------------------\n",
      "loss: 1.052176  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050385 \n",
      "\n",
      "Epoch 855\n",
      "-------------------------------\n",
      "loss: 1.052152  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050359 \n",
      "\n",
      "Epoch 856\n",
      "-------------------------------\n",
      "loss: 1.052128  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050334 \n",
      "\n",
      "Epoch 857\n",
      "-------------------------------\n",
      "loss: 1.052104  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050308 \n",
      "\n",
      "Epoch 858\n",
      "-------------------------------\n",
      "loss: 1.052080  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050283 \n",
      "\n",
      "Epoch 859\n",
      "-------------------------------\n",
      "loss: 1.052057  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050257 \n",
      "\n",
      "Epoch 860\n",
      "-------------------------------\n",
      "loss: 1.052033  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050232 \n",
      "\n",
      "Epoch 861\n",
      "-------------------------------\n",
      "loss: 1.052009  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050207 \n",
      "\n",
      "Epoch 862\n",
      "-------------------------------\n",
      "loss: 1.051985  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050182 \n",
      "\n",
      "Epoch 863\n",
      "-------------------------------\n",
      "loss: 1.051962  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050156 \n",
      "\n",
      "Epoch 864\n",
      "-------------------------------\n",
      "loss: 1.051938  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050131 \n",
      "\n",
      "Epoch 865\n",
      "-------------------------------\n",
      "loss: 1.051914  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050106 \n",
      "\n",
      "Epoch 866\n",
      "-------------------------------\n",
      "loss: 1.051890  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050081 \n",
      "\n",
      "Epoch 867\n",
      "-------------------------------\n",
      "loss: 1.051867  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050056 \n",
      "\n",
      "Epoch 868\n",
      "-------------------------------\n",
      "loss: 1.051843  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050031 \n",
      "\n",
      "Epoch 869\n",
      "-------------------------------\n",
      "loss: 1.051820  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.050006 \n",
      "\n",
      "Epoch 870\n",
      "-------------------------------\n",
      "loss: 1.051796  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049981 \n",
      "\n",
      "Epoch 871\n",
      "-------------------------------\n",
      "loss: 1.051773  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049956 \n",
      "\n",
      "Epoch 872\n",
      "-------------------------------\n",
      "loss: 1.051749  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049931 \n",
      "\n",
      "Epoch 873\n",
      "-------------------------------\n",
      "loss: 1.051726  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049906 \n",
      "\n",
      "Epoch 874\n",
      "-------------------------------\n",
      "loss: 1.051702  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049881 \n",
      "\n",
      "Epoch 875\n",
      "-------------------------------\n",
      "loss: 1.051679  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049856 \n",
      "\n",
      "Epoch 876\n",
      "-------------------------------\n",
      "loss: 1.051656  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049831 \n",
      "\n",
      "Epoch 877\n",
      "-------------------------------\n",
      "loss: 1.051632  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049806 \n",
      "\n",
      "Epoch 878\n",
      "-------------------------------\n",
      "loss: 1.051609  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049782 \n",
      "\n",
      "Epoch 879\n",
      "-------------------------------\n",
      "loss: 1.051586  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049757 \n",
      "\n",
      "Epoch 880\n",
      "-------------------------------\n",
      "loss: 1.051563  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049732 \n",
      "\n",
      "Epoch 881\n",
      "-------------------------------\n",
      "loss: 1.051540  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049708 \n",
      "\n",
      "Epoch 882\n",
      "-------------------------------\n",
      "loss: 1.051517  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049683 \n",
      "\n",
      "Epoch 883\n",
      "-------------------------------\n",
      "loss: 1.051494  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049658 \n",
      "\n",
      "Epoch 884\n",
      "-------------------------------\n",
      "loss: 1.051471  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049634 \n",
      "\n",
      "Epoch 885\n",
      "-------------------------------\n",
      "loss: 1.051447  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049609 \n",
      "\n",
      "Epoch 886\n",
      "-------------------------------\n",
      "loss: 1.051424  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049585 \n",
      "\n",
      "Epoch 887\n",
      "-------------------------------\n",
      "loss: 1.051401  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049560 \n",
      "\n",
      "Epoch 888\n",
      "-------------------------------\n",
      "loss: 1.051378  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049536 \n",
      "\n",
      "Epoch 889\n",
      "-------------------------------\n",
      "loss: 1.051355  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049512 \n",
      "\n",
      "Epoch 890\n",
      "-------------------------------\n",
      "loss: 1.051333  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049487 \n",
      "\n",
      "Epoch 891\n",
      "-------------------------------\n",
      "loss: 1.051310  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049463 \n",
      "\n",
      "Epoch 892\n",
      "-------------------------------\n",
      "loss: 1.051287  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049439 \n",
      "\n",
      "Epoch 893\n",
      "-------------------------------\n",
      "loss: 1.051264  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049414 \n",
      "\n",
      "Epoch 894\n",
      "-------------------------------\n",
      "loss: 1.051242  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049390 \n",
      "\n",
      "Epoch 895\n",
      "-------------------------------\n",
      "loss: 1.051219  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049366 \n",
      "\n",
      "Epoch 896\n",
      "-------------------------------\n",
      "loss: 1.051196  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049342 \n",
      "\n",
      "Epoch 897\n",
      "-------------------------------\n",
      "loss: 1.051174  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049318 \n",
      "\n",
      "Epoch 898\n",
      "-------------------------------\n",
      "loss: 1.051151  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049293 \n",
      "\n",
      "Epoch 899\n",
      "-------------------------------\n",
      "loss: 1.051128  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049269 \n",
      "\n",
      "Epoch 900\n",
      "-------------------------------\n",
      "loss: 1.051106  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049245 \n",
      "\n",
      "Epoch 901\n",
      "-------------------------------\n",
      "loss: 1.051083  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049221 \n",
      "\n",
      "Epoch 902\n",
      "-------------------------------\n",
      "loss: 1.051061  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049197 \n",
      "\n",
      "Epoch 903\n",
      "-------------------------------\n",
      "loss: 1.051038  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049173 \n",
      "\n",
      "Epoch 904\n",
      "-------------------------------\n",
      "loss: 1.051016  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049149 \n",
      "\n",
      "Epoch 905\n",
      "-------------------------------\n",
      "loss: 1.050993  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049126 \n",
      "\n",
      "Epoch 906\n",
      "-------------------------------\n",
      "loss: 1.050971  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049102 \n",
      "\n",
      "Epoch 907\n",
      "-------------------------------\n",
      "loss: 1.050949  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049078 \n",
      "\n",
      "Epoch 908\n",
      "-------------------------------\n",
      "loss: 1.050926  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049054 \n",
      "\n",
      "Epoch 909\n",
      "-------------------------------\n",
      "loss: 1.050904  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.049030 \n",
      "\n",
      "Epoch 910\n",
      "-------------------------------\n",
      "loss: 1.050882  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.049007 \n",
      "\n",
      "Epoch 911\n",
      "-------------------------------\n",
      "loss: 1.050859  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048983 \n",
      "\n",
      "Epoch 912\n",
      "-------------------------------\n",
      "loss: 1.050837  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048959 \n",
      "\n",
      "Epoch 913\n",
      "-------------------------------\n",
      "loss: 1.050815  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048936 \n",
      "\n",
      "Epoch 914\n",
      "-------------------------------\n",
      "loss: 1.050793  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048912 \n",
      "\n",
      "Epoch 915\n",
      "-------------------------------\n",
      "loss: 1.050771  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048888 \n",
      "\n",
      "Epoch 916\n",
      "-------------------------------\n",
      "loss: 1.050749  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048865 \n",
      "\n",
      "Epoch 917\n",
      "-------------------------------\n",
      "loss: 1.050727  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048841 \n",
      "\n",
      "Epoch 918\n",
      "-------------------------------\n",
      "loss: 1.050705  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048818 \n",
      "\n",
      "Epoch 919\n",
      "-------------------------------\n",
      "loss: 1.050683  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048794 \n",
      "\n",
      "Epoch 920\n",
      "-------------------------------\n",
      "loss: 1.050661  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048771 \n",
      "\n",
      "Epoch 921\n",
      "-------------------------------\n",
      "loss: 1.050639  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048748 \n",
      "\n",
      "Epoch 922\n",
      "-------------------------------\n",
      "loss: 1.050617  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048724 \n",
      "\n",
      "Epoch 923\n",
      "-------------------------------\n",
      "loss: 1.050595  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048701 \n",
      "\n",
      "Epoch 924\n",
      "-------------------------------\n",
      "loss: 1.050573  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048678 \n",
      "\n",
      "Epoch 925\n",
      "-------------------------------\n",
      "loss: 1.050551  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048654 \n",
      "\n",
      "Epoch 926\n",
      "-------------------------------\n",
      "loss: 1.050529  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048631 \n",
      "\n",
      "Epoch 927\n",
      "-------------------------------\n",
      "loss: 1.050507  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048608 \n",
      "\n",
      "Epoch 928\n",
      "-------------------------------\n",
      "loss: 1.050486  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048585 \n",
      "\n",
      "Epoch 929\n",
      "-------------------------------\n",
      "loss: 1.050464  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048562 \n",
      "\n",
      "Epoch 930\n",
      "-------------------------------\n",
      "loss: 1.050442  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048539 \n",
      "\n",
      "Epoch 931\n",
      "-------------------------------\n",
      "loss: 1.050421  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048515 \n",
      "\n",
      "Epoch 932\n",
      "-------------------------------\n",
      "loss: 1.050399  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048492 \n",
      "\n",
      "Epoch 933\n",
      "-------------------------------\n",
      "loss: 1.050378  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048469 \n",
      "\n",
      "Epoch 934\n",
      "-------------------------------\n",
      "loss: 1.050356  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048446 \n",
      "\n",
      "Epoch 935\n",
      "-------------------------------\n",
      "loss: 1.050334  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048423 \n",
      "\n",
      "Epoch 936\n",
      "-------------------------------\n",
      "loss: 1.050313  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048401 \n",
      "\n",
      "Epoch 937\n",
      "-------------------------------\n",
      "loss: 1.050291  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048378 \n",
      "\n",
      "Epoch 938\n",
      "-------------------------------\n",
      "loss: 1.050270  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048355 \n",
      "\n",
      "Epoch 939\n",
      "-------------------------------\n",
      "loss: 1.050248  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048332 \n",
      "\n",
      "Epoch 940\n",
      "-------------------------------\n",
      "loss: 1.050227  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048309 \n",
      "\n",
      "Epoch 941\n",
      "-------------------------------\n",
      "loss: 1.050205  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048286 \n",
      "\n",
      "Epoch 942\n",
      "-------------------------------\n",
      "loss: 1.050184  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048263 \n",
      "\n",
      "Epoch 943\n",
      "-------------------------------\n",
      "loss: 1.050163  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048241 \n",
      "\n",
      "Epoch 944\n",
      "-------------------------------\n",
      "loss: 1.050141  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048218 \n",
      "\n",
      "Epoch 945\n",
      "-------------------------------\n",
      "loss: 1.050120  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048195 \n",
      "\n",
      "Epoch 946\n",
      "-------------------------------\n",
      "loss: 1.050099  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048173 \n",
      "\n",
      "Epoch 947\n",
      "-------------------------------\n",
      "loss: 1.050078  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048150 \n",
      "\n",
      "Epoch 948\n",
      "-------------------------------\n",
      "loss: 1.050056  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048127 \n",
      "\n",
      "Epoch 949\n",
      "-------------------------------\n",
      "loss: 1.050035  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048105 \n",
      "\n",
      "Epoch 950\n",
      "-------------------------------\n",
      "loss: 1.050014  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048082 \n",
      "\n",
      "Epoch 951\n",
      "-------------------------------\n",
      "loss: 1.049993  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048060 \n",
      "\n",
      "Epoch 952\n",
      "-------------------------------\n",
      "loss: 1.049972  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048037 \n",
      "\n",
      "Epoch 953\n",
      "-------------------------------\n",
      "loss: 1.049951  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.048015 \n",
      "\n",
      "Epoch 954\n",
      "-------------------------------\n",
      "loss: 1.049930  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047992 \n",
      "\n",
      "Epoch 955\n",
      "-------------------------------\n",
      "loss: 1.049909  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047970 \n",
      "\n",
      "Epoch 956\n",
      "-------------------------------\n",
      "loss: 1.049888  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047948 \n",
      "\n",
      "Epoch 957\n",
      "-------------------------------\n",
      "loss: 1.049867  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047925 \n",
      "\n",
      "Epoch 958\n",
      "-------------------------------\n",
      "loss: 1.049846  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047903 \n",
      "\n",
      "Epoch 959\n",
      "-------------------------------\n",
      "loss: 1.049825  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047881 \n",
      "\n",
      "Epoch 960\n",
      "-------------------------------\n",
      "loss: 1.049804  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047859 \n",
      "\n",
      "Epoch 961\n",
      "-------------------------------\n",
      "loss: 1.049783  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047836 \n",
      "\n",
      "Epoch 962\n",
      "-------------------------------\n",
      "loss: 1.049762  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047814 \n",
      "\n",
      "Epoch 963\n",
      "-------------------------------\n",
      "loss: 1.049742  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047792 \n",
      "\n",
      "Epoch 964\n",
      "-------------------------------\n",
      "loss: 1.049721  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047770 \n",
      "\n",
      "Epoch 965\n",
      "-------------------------------\n",
      "loss: 1.049700  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047748 \n",
      "\n",
      "Epoch 966\n",
      "-------------------------------\n",
      "loss: 1.049679  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047726 \n",
      "\n",
      "Epoch 967\n",
      "-------------------------------\n",
      "loss: 1.049659  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047704 \n",
      "\n",
      "Epoch 968\n",
      "-------------------------------\n",
      "loss: 1.049638  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.047682 \n",
      "\n",
      "Epoch 969\n",
      "-------------------------------\n",
      "loss: 1.049617  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.047660 \n",
      "\n",
      "Epoch 970\n",
      "-------------------------------\n",
      "loss: 1.049597  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.047638 \n",
      "\n",
      "Epoch 971\n",
      "-------------------------------\n",
      "loss: 1.049576  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.047616 \n",
      "\n",
      "Epoch 972\n",
      "-------------------------------\n",
      "loss: 1.049556  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.047594 \n",
      "\n",
      "Epoch 973\n",
      "-------------------------------\n",
      "loss: 1.049535  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.047572 \n",
      "\n",
      "Epoch 974\n",
      "-------------------------------\n",
      "loss: 1.049515  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.047550 \n",
      "\n",
      "Epoch 975\n",
      "-------------------------------\n",
      "loss: 1.049494  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047529 \n",
      "\n",
      "Epoch 976\n",
      "-------------------------------\n",
      "loss: 1.049474  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047507 \n",
      "\n",
      "Epoch 977\n",
      "-------------------------------\n",
      "loss: 1.049453  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047485 \n",
      "\n",
      "Epoch 978\n",
      "-------------------------------\n",
      "loss: 1.049433  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047463 \n",
      "\n",
      "Epoch 979\n",
      "-------------------------------\n",
      "loss: 1.049412  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047442 \n",
      "\n",
      "Epoch 980\n",
      "-------------------------------\n",
      "loss: 1.049392  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047420 \n",
      "\n",
      "Epoch 981\n",
      "-------------------------------\n",
      "loss: 1.049372  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047398 \n",
      "\n",
      "Epoch 982\n",
      "-------------------------------\n",
      "loss: 1.049352  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047377 \n",
      "\n",
      "Epoch 983\n",
      "-------------------------------\n",
      "loss: 1.049331  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047355 \n",
      "\n",
      "Epoch 984\n",
      "-------------------------------\n",
      "loss: 1.049311  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047334 \n",
      "\n",
      "Epoch 985\n",
      "-------------------------------\n",
      "loss: 1.049291  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047312 \n",
      "\n",
      "Epoch 986\n",
      "-------------------------------\n",
      "loss: 1.049271  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047291 \n",
      "\n",
      "Epoch 987\n",
      "-------------------------------\n",
      "loss: 1.049251  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047269 \n",
      "\n",
      "Epoch 988\n",
      "-------------------------------\n",
      "loss: 1.049231  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047248 \n",
      "\n",
      "Epoch 989\n",
      "-------------------------------\n",
      "loss: 1.049211  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047226 \n",
      "\n",
      "Epoch 990\n",
      "-------------------------------\n",
      "loss: 1.049190  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047205 \n",
      "\n",
      "Epoch 991\n",
      "-------------------------------\n",
      "loss: 1.049170  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047183 \n",
      "\n",
      "Epoch 992\n",
      "-------------------------------\n",
      "loss: 1.049150  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047162 \n",
      "\n",
      "Epoch 993\n",
      "-------------------------------\n",
      "loss: 1.049130  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047141 \n",
      "\n",
      "Epoch 994\n",
      "-------------------------------\n",
      "loss: 1.049111  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047120 \n",
      "\n",
      "Epoch 995\n",
      "-------------------------------\n",
      "loss: 1.049091  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047098 \n",
      "\n",
      "Epoch 996\n",
      "-------------------------------\n",
      "loss: 1.049071  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047077 \n",
      "\n",
      "Epoch 997\n",
      "-------------------------------\n",
      "loss: 1.049051  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047056 \n",
      "\n",
      "Epoch 998\n",
      "-------------------------------\n",
      "loss: 1.049031  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047035 \n",
      "\n",
      "Epoch 999\n",
      "-------------------------------\n",
      "loss: 1.049011  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.047013 \n",
      "\n",
      "Epoch 1000\n",
      "-------------------------------\n",
      "loss: 1.048991  [ 1000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.046992 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_data_loader, model, loss_fn, optimizer)\n",
    "    test(train_data_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
